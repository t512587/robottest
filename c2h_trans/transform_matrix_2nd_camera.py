import pyrealsense2 as rs
import numpy as np
import cv2
import datetime
import json
import os
from pymycobot.elephantrobot import ElephantRobot

# === åˆå§‹åŒ–é€£ç·š ===
elephant_client = ElephantRobot("192.168.1.159", 5001)
elephant_client.start_client()
print("ElephantRobotç›®å‰åº§æ¨™ï¼š", elephant_client.get_coords())

# === åˆå§‹åŒ– RealSense ç›¸æ©Ÿ ===
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
pipeline.start(config)

# === å–å¾—å…§åƒ ===
profile = pipeline.get_active_profile()
video_stream_profile = profile.get_stream(rs.stream.color)
intr = video_stream_profile.as_video_stream_profile().get_intrinsics()

camera_matrix = np.array([
    [intr.fx, 0, intr.ppx],
    [0, intr.fy, intr.ppy],
    [0, 0, 1]
])
dist_coeffs = np.zeros((5, 1))

# === ArUco è¨­å®š ===
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
parameters = cv2.aruco.DetectorParameters()
marker_length = 0.04  # å–®ä½: å…¬å°º

# === è³‡æ–™å„²å­˜ ===
output_data = []
save_dir = "handeye_records"
os.makedirs(save_dir, exist_ok=True)

print("\n=== æ‰‹çœ¼æ¨™å®šè³‡æ–™è¨˜éŒ„ç³»çµ± ===")
print("s - è¨˜éŒ„ ArUco + æ©Ÿæ¢°æ‰‹åˆå§‹å§¿æ…‹")
print("m - è¨˜éŒ„è©²é»ç§»å‹•å¾Œçš„å§¿æ…‹")
print("v - æŸ¥çœ‹å·²è¨˜éŒ„è³‡æ–™")
print("r - é‡ç½®è³‡æ–™")
print("q - é›¢é–‹ä¸¦å„²å­˜")
print("=" * 40)

try:
    current_index = 0

    while True:
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            continue

        color_image = np.asanyarray(color_frame.get_data())
        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)

        corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        if ids is not None:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_length, camera_matrix, dist_coeffs)

            for i in range(len(ids)):
                cv2.aruco.drawDetectedMarkers(color_image, corners)
                cv2.drawFrameAxes(color_image, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.03)
                corner = corners[i][0]
                cv2.putText(color_image, f"ID: {ids[i][0]}",
                            (int(corner[0][0]), int(corner[0][1])-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        cv2.imshow("Hand-Eye Calibration Collector", color_image)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('q'):
            break

        elif key == ord('s') and ids is not None:
            # åªè¨˜éŒ„ç¬¬ä¸€å€‹ ArUco
            rvec = rvecs[0][0].tolist()
            tvec = (tvecs[0][0] * 1000).tolist()  # å°‡ m è½‰æ›ç‚º mm
            marker_id = int(ids[0][0])
            robot_pose = elephant_client.get_coords()

            entry = {
                "marker_id": marker_id,
                "aruco_tvec": tvec,
                "aruco_rvec": rvec,
                "robot_pose_at_detect": robot_pose,
                "robot_pose_after_move": None
            }

            output_data.append(entry)
            current_index = len(output_data) - 1

            print(f"\nâœ… å·²è¨˜éŒ„ç¬¬ {current_index + 1} ç­† (ID: {marker_id})")
            print(f"ArUco tvec (m): {tvec}")
            print(f"ArUco rvec: {rvec}")
            print(f"æ‰‹è‡‚å§¿æ…‹: {robot_pose}")

        elif key == ord('m') and output_data and output_data[current_index]["robot_pose_after_move"] is None:
            moved_pose = elephant_client.get_coords()
            output_data[current_index]["robot_pose_after_move"] = moved_pose
            print(f"ğŸ” å·²è£œä¸Šç§»å‹•å¾Œæ‰‹è‡‚å§¿æ…‹ï¼š{moved_pose}")

        elif key == ord('v'):
            print(f"\nğŸ“‹ å·²è¨˜éŒ„ {len(output_data)} ç­†è³‡æ–™ï¼š")
            for i, d in enumerate(output_data):
                moved = "âœ…" if d["robot_pose_after_move"] else "â³"
                print(f"  ç¬¬ {i+1} ç­† - ID: {d['marker_id']} {moved}")

        elif key == ord('r'):
            output_data = []
            print("ğŸ”„ å·²æ¸…ç©ºæ‰€æœ‰è¨˜éŒ„")

finally:
    pipeline.stop()
    cv2.destroyAllWindows()

    if output_data:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(save_dir, f"handeye_record_{timestamp}.json")
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=2)
        print(f"\nğŸ’¾ å·²å„²å­˜ {len(output_data)} ç­†è³‡æ–™è‡³ {filename}")
    print("ğŸ“Œ ç¨‹å¼çµæŸ")
